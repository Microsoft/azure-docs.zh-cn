---
title: 评估并提高自定义语音识别准确度 - 语音服务
titleSuffix: Azure Cognitive Services
description: 本文档介绍如何以定量方式度量和提高我们的语音转文本模型或你的自定义模型的质量。 需要使用音频 + 人为标记的听录数据来测试准确度，并应提供 30 分钟到 5 小时的代表性音频。
services: cognitive-services
author: trevorbye
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 11/11/2020
ms.author: trbye
ms.openlocfilehash: 54a54dccd82e4f6cfd72a1cc8a71b51f9fd4ed95
ms.sourcegitcommit: 697638c20ceaf51ec4ebd8f929c719c1e630f06f
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 01/04/2021
ms.locfileid: "97857352"
---
# <a name="evaluate-and-improve-custom-speech-accuracy"></a>评估并提升自定义语音识别准确度

本文档介绍如何以定量方式度量和提高 Microsoft 的语音转文本模型或你自己的自定义模型的准确度。 需要使用音频 + 人为标记的听录数据来测试准确度，并应提供 30 分钟到 5 小时的代表性音频。

## <a name="evaluate-custom-speech-accuracy"></a>评估自定义语音识别准确度

用于度量模型准确度的行业标准是误字率 (WER)。 计算 WER 时，先对识别过程中标识的错误单词计数，然后将其除以人为标记的听录中提供的单词的总数（下面显示为 N）。 最后将该数字乘以 100%。

![WER 公式](./media/custom-speech/custom-speech-wer-formula.png)

错误标识的单词分为三个类别：

* 插入 (I)：在假设脚本中错误添加的单词
* 删除 (D)：在假设脚本中未检测到的单词
* 替换 (S)：在引用和假设之间替换的单词

下面是一个示例：

![错误标识的单词的示例](./media/custom-speech/custom-speech-dis-words.png)

如果要在本地复制 WER 度量，可以使用 [SCTK](https://github.com/usnistgov/SCTK)中的 sclite。

## <a name="resolve-errors-and-improve-wer"></a>解决错误并降低 WER

可以使用机器识别结果中的 WER 来评估与应用、工具或产品配合使用的模型的质量。 WER 为 5%-10% 表明质量好，可以使用。 WER 为 20% 可以接受，但可能需要考虑进行更多的训练。 WER 为 30% 或以上表明质量差，需要自定义和训练。

错误的分布情况很重要。 如果遇到许多删除错误，通常是因为音频信号强度弱。 若要解决此问题，需要在收集音频数据时更靠近源。 插入错误意味着音频是在嘈杂环境中记录的，并且可能存在串音，导致识别问题。 如果以人为标记的听录或相关文本形式提供特定于领域的术语样本不足，则通常会遇到替换错误。

可以通过分析单个文件来确定存在的错误的类型，以及哪些错误是特定文件独有的。 在文件级别了解问题将有助于你确定改进目标。

## <a name="create-a-test"></a>创建测试

若要测试 Microsoft 的语音转文本基线模型或你训练的自定义模型的质量，可以将两个模型并排比较一下，评估准确度。 此比较包括 WER 和识别结果。 通常情况下，自定义模型会与 Microsoft 的基线模型比较。

若要并排评估模型，请执行以下操作：

1. 登录到[自定义语音识别门户](https://speech.microsoft.com/customspeech)。
2. 导航到“语音转文本”>“自定义语音识别”> [项目名称] >“测试”。
3. 单击“添加测试”。
4. 选择“评估准确度”。 为测试提供名称和说明，然后选择你的音频和人为标记的听录数据集。
5. 选择最多两个要测试的模型。
6. 单击 **创建**。

成功创建测试后，可以并排比较结果。

### <a name="side-by-side-comparison"></a>并排比较

测试完成（状态更改为“成功”即表明完成）后，就可以找到测试中包括的两个模型的 WER 值。 单击测试名称可查看测试详细信息页。 该详细信息页会列出数据集中的所有言语，指示两个模型的识别结果以及提供的数据集中的听录。 可以通过切换各种错误类型（包括插入、删除和替换）来查看并排比较的结果。 通过听音频并比较每个列（显示人为标记的听录和两个语音转文本模型的结果）中的识别结果，你可以确定哪个模型符合自己的需求，以及需要在哪些方面进行更多的训练和改进。

## <a name="improve-custom-speech-accuracy"></a>提升自定义语音准确度

语音识别方案因音频质量和语言 (词汇和讲话风格) 不同。 下表检查了四种常见方案：

| 方案 | 音频质量 | 词汇 | 讲话风格 |
|----------|---------------|------------|----------------|
| 呼叫中心 | 低、8 kHz，可以是1个音频频道的2人，可以压缩 | 缩小，对于域和产品是唯一的 | 会话，松散结构化 |
| 语音助手 (如 Cortana 或驱动器到 windows)  | 高、16 kHz | 实体重型 (歌曲标题、产品、位置)  | 明确表述的单词和短语 |
| 听写 (即时消息、注释、搜索)  | 高、16 kHz | Varied | 注意-执行 |
| 视频隐藏式字幕 | 不同，包括各种麦克风使用、添加的音乐 | 不同会议、recited 语音、音乐歌词 | 读取、准备或松散结构化 |

不同的方案会产生不同的质量结果。 下表检查了这四种方案中的内容如何以 [word 错误率 (WER) ](how-to-custom-speech-evaluate-data.md)。 下表显示了在每个方案中最常见的错误类型。

| 方案 | 语音识别质量 | 插入错误 | 删除错误 | 替换错误 |
|----------|----------------------------|------------------|-----------------|---------------------|
| 呼叫中心 | 中型 ( # A0 30% WER)  | 低，但其他人在后台对话时除外 | 可能很高。 呼叫中心可能会噪音，重叠的扬声器可能会混淆模型 | 中等。 产品和人员的名称可能导致这些错误 |
| 语音助手 | 高 (可以 < 10% WER)  | 低 | 低 | Medium，因为歌曲标题、产品名称或位置 |
| 听写 | 高 (可以 < 10% WER)  | 低 | 低 | 高 |
| 视频隐藏式字幕 | 取决于视频类型 (可以 < 50% WER)  | 低 | 可能由于音乐、噪音、麦克风质量而较高 | 术语可能导致这些错误 |

确定 WER 的组件 (插入、删除和替换错误的数目) 可帮助确定要添加哪种类型的数据来改进模型。 使用 [自定义语音门户](https://speech.microsoft.com/customspeech) 查看基线模型的质量。 门户报告在 WER 质量速率下组合的插入、替换和删除错误率。

## <a name="improve-model-recognition"></a>改善模型识别

可以通过在[自定义语音识别门户](https://speech.microsoft.com/customspeech)中添加训练数据来减少识别错误。 

计划通过定期添加源材料来维护自定义模型。 自定义模型需要额外的训练来了解对实体的更改。 例如，可能需要更新的产品名称、歌曲名称或新的服务位置。

以下各节介绍了其他每种类型的训练数据如何减少错误。

### <a name="add-related-text-sentences"></a>添加相关的文本句子

训练新的自定义模型时，首先添加相关的文本，以改善域特定词和短语的识别。 相关的文本句子可以通过在上下文中显示来减少与常见词和域特定单词的 misrecognition 相关的替换错误。 特定领域的字词可能不太常见或者属于杜撰的字词，但其发音必须易于识别。

> [!NOTE]
> 避免相关的文本句子包含无法识别的字符或字词等干扰因素。

### <a name="add-audio-with-human-labeled-transcripts"></a>添加具有人为标记的脚本的音频

如果音频来自目标用例，则带有人为标记的脚本的音频可提供最大的准确性改进。 示例必须涵盖整个语音范围。 例如，零售商店的呼叫中心会在夏季接到大量有关泳装和太阳镜的电话。 确保示例包括要检测的整个语音范围。

考虑以下细节：

* 自定义语音识别只能捕获字词上下文来减少替换错误，而不是插入或删除错误。
* 避免使用包含脚本错误的示例，但使用包含各种音频质量的示例。
* 避免使用与问题领域无关的句子。 不相关的句子可能损坏模型。
* 当脚本质量参差不齐时，可以复制非常好的句子（例如包含关键短语的优秀脚本）以增加其权重。
* 语音服务将自动使用这些脚本来改善域特定词和短语的识别，就好像它们是作为相关文本添加的。
* 如果音频也难以理解，则通过音频进行培训将获得最大优势。 在大多数情况下，只需使用相关文本即可开始培训。
* 完成训练操作可能需要几天。 若要改善培训速度，请确保在 [具有专用硬件](custom-speech-overview.md#set-up-your-azure-account) 培训的区域中创建语音服务订阅。

> [!NOTE]
> 并非所有基本模型都支持带有音频的培训。 如果基本模型不支持该模型，则语音服务将只使用脚本中的文本并忽略音频。

### <a name="add-new-words-with-pronunciation"></a>添加具有发音的新字词

杜撰的字词或高度专业化的字词可能具有独特发音。 如果可以将这类字词分解为更小的字词，则可以识别这些字词。  例如，若要识别 Xbox，可以发音为 X box。 此方法不会提高总体准确性，但可以增加对这些关键字的识别度。

> [!NOTE]
> 此方法目前仅适用于某些语言。 有关详细信息，请参阅[语音转文本表](language-support.md)中的发音自定义。

## <a name="sources-by-scenario"></a>按应用场景的源

下表显示了语音识别方案，并列出了上面列出的三个定型内容类别中要考虑的源材料。

| 方案 | 相关文本句子 | 音频和人为标记的听录内容 | 带有发音的新词 |
|----------|------------------------|------------------------------|------------------------------|
| 呼叫中心             | 营销文档、网站、与呼叫中心活动相关的产品评审 | 呼叫中心呼叫转录 | 具有不明确发音的字词 (参阅上述 Xbox)  |
| 语音助手         | 使用命令和实体的所有组合来列出句子 | 将语音朗读命令记录到设备中，将转录记录到文本中 | 具有唯一发音的 (电影、歌曲、产品) 的名称 |
| 听写               | 书面输入，如即时消息或电子邮件 | 类似于上面 | 类似于上面 |
| 视频隐藏式字幕 | 电视节目脚本、电影、营销内容、视频摘要 | 视频的确切脚本 | 类似于上面 |

## <a name="next-steps"></a>后续步骤

* [训练和部署模型](how-to-custom-speech-train-model.md)

## <a name="additional-resources"></a>其他资源

* [准备和测试数据](./how-to-custom-speech-test-and-train.md)
* [检查数据](how-to-custom-speech-inspect-data.md)