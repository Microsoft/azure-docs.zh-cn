---
title: 创建自定义语音 - 语音服务
titleSuffix: Azure Cognitive Services
description: 如果你已准备好上传数据，请转到自定义语音门户。 创建或选择一个自定义语音项目。 该项目必须与你打算用于语音训练的数据共享正确的语言/区域设置和性别属性。
services: cognitive-services
author: erhopf
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 11/04/2019
ms.author: erhopf
ms.openlocfilehash: 541448f08e4ce9961d34063dcc225bf89d969a73
ms.sourcegitcommit: f28ebb95ae9aaaff3f87d8388a09b41e0b3445b5
ms.translationtype: HT
ms.contentlocale: zh-CN
ms.lasthandoff: 03/30/2021
ms.locfileid: "101703365"
---
# <a name="create-a-custom-voice"></a>创建自定义语音

[为自定义语音准备数据](how-to-custom-voice-prepare-data.md)中已介绍可用于训练自定义语音的不同数据类型，以及不同的格式要求。 准备好数据后，可以开始将其上传到[自定义语音门户](https://aka.ms/custom-voice-portal)；也可以通过自定义语音训练 API 上传。 本文介绍通过门户训练自定义语音的步骤。

> [!NOTE]
> 本页假设你已阅读[自定义语音入门](how-to-custom-voice.md)和[为自定义语音准备数据](how-to-custom-voice-prepare-data.md)，并已创建一个自定义语音项目。

检查自定义语音支持的语言：[支持自定义的语言](language-support.md#customization)。

## <a name="upload-your-datasets"></a>上传数据集

如果你已准备好上传数据，请转到[自定义语音门户](https://aka.ms/custom-voice-portal)。 创建或选择一个自定义语音项目。 该项目必须与你打算用于语音训练的数据共享正确的语言/区域设置和性别属性。 例如，如果你的音频录制内容是使用英式口音录制的，请选择 `en-GB`。

转到“数据”选项卡并单击“上传数据”。  在向导中，选择与准备好的数据匹配的适当数据类型。

上传的每个数据集必须符合所选数据类型的要求。 在上传数据之前，必须正确设置数据的格式。 这可以确保自定义语音服务准确处理数据。 转到[为自定义语音准备数据](how-to-custom-voice-prepare-data.md)，并确保数据的格式正确。

> [!NOTE]
> 免费订阅 (F0) 用户可以同时上传两个数据集。 标准订阅 (S0) 用户可以同时上传五个数据集。 如果达到限制，请先等待，直至至少其中一个数据集导入完毕。 然后重试。

> [!NOTE]
> 每个订阅允许导入的数据集的最大数目为 10 个（对于免费订阅 (F0) 用户）和 500 个（对于标准订阅 (S0) 用户）.zip 文件。

点击“上传”按钮后，系统会自动验证数据集。 数据验证包括针对音频文件执行一系列检查以验证文件格式、大小和采样率。 修复出现的任何错误，然后重新提交。 成功发起数据导入请求后，数据表中应会出现一个对应于刚刚上传的数据集的条目。

下表显示了已导入数据集的处理状态：

| 状态 | 含义 |
| ----- | ------- |
| 正在处理 | 已收到并正在处理数据集。 |
| 已成功 | 已验证数据集，现在可以使用它来生成语音模型。 |
| 已失败 | 数据集在处理过程中因多种原因（例如文件错误、数据问题或网络问题）而失败。 |

验证完成后，可以在“言语”列中看到每个数据集的已匹配言语总数。 如果所选数据类型需要进行长音频分段，此列只会反映已根据脚本或通过语音听录服务分段的言语。 可以进一步下载已验证的数据集，以查看已成功导入的言语的详细结果及其映射脚本。 提示：长音频分段可能需要一小时以上才能完成数据处理。

在数据详细信息视图中，可以进一步检查每个数据集的发音分数和噪音级别。 发音评分范围为 0 到 100。 评分低于 70 通常表示语音错误或脚本不匹配。 口音重可能会降低发音分数，影响生成的数字语音。

信噪比 (SNR) 高表明音频中的噪音少。 通过专业录音棚录音通常可以达到 50+ 的 SNR。 音频的 SNR 低于 20 可能导致生成的语音中出现明显的噪音。

考虑重写录制发音分数低或信噪比不佳的表述。 如果无法重新录制，可以从数据集中排除这些话语。

> [!NOTE]
> 如果使用的是自定义神经语音，则必须在“配音员”选项卡中注册配音员。准备录制脚本时，请确保包含以下句子，以获得配音员同意使用其语音数据创建 TTS 语音模型并生成合成语音的确认。 “我[说出你的名字和姓氏]知道，[说出公司名称]将使用我的声音录音来创建和使用我的声音的合成版本。”
这句话将用于验证训练数据集中的录制内容是否由作出同意的同一人完成。 [在此处阅读有关如何处理数据以及如何完成配音员验证的详细信息](/legal/cognitive-services/speech-service/custom-neural-voice/data-privacy-security-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext)。 

## <a name="build-your-custom-voice-model"></a>生成自定义语音模型

验证数据集后，可以使用它来生成自定义语音模型。

1.  导航到“文本转语音”>“自定义语音”> [项目名称] >“模型”。

2.  单击“训练模型”。

3.  接下来，输入 **名称** 和 **说明** 以帮助识别此模型。

    请谨慎选择名称。 此处输入的名称将是在 SSML 输入过程中在请求中指定语音合成所需语音时使用的名称。 只允许字母、数字以及部分标点字符，例如“-”、“\_”和“,”。 请对不同的语音模型使用不同的名称。

    通常使用“说明”字段来记录创建模型时所使用的数据集的名称。

4.  在“选择训练数据”页中，选择一个或多个用于训练的数据集。 提交言语之前请检查其数目。 对于 en-US 和 zh-CN 语音模型，可以使用“自适应”训练方法从任意数目的言语着手。 对于其他区域设置，你必须选择超过 2,000 个言语，才能使用标准层（包括“统计参数”和“连续式”训练方法）来训练语音，并使用超过 300 个言语来训练自定义神经语音。 

    > [!NOTE]
    > 在训练中将会删除重复的音频名称。 确保所选的数据集不会在多个 .zip 文件中包含相同的音频名称。

    > [!TIP]
    > 为获得优质结果，必须使用同一讲话者的数据集。 不同训练方法需要不同的训练数据大小。 若要使用“统计参数”方法来训练模型，则需要至少 2,000 个不同的言语。 “连续式”方法需要 6,000 个言语，而“神经”方法需要的最小数据大小为 300 个言语。

5. 在下一步中选择“训练方法”。 

    > [!NOTE]
    > 如果要训练神经语音，你必须指定配音员个人资料，其中包含配音员提供的语音同意文件，确认使用他/她的语音数据来训练一个自定义语音模型。 自定义神经语音只能在有限的访问权限下使用。 请确保你了解[负责任的 AI 使用原则](/legal/cognitive-services/speech-service/custom-neural-voice/limited-access-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext)并[在此处应用访问权限](https://aka.ms/customneural)。 
    
    在此页上，你还可以选择上传脚本以进行测试。 测试脚本必须是小于 1 Mb 的 txt 文件。 支持的编码格式包括 ANSI/ASCII、UTF-8、UTF-8-BOM、UTF-16-LE 或 UTF-16-BE。 每个言语段落生成一个单独的音频。 如果要将所有句子合并为一个音频，请将它们放在一个段落中。 

6. 单击“训练”开始创建语音模型。

“训练”表将显示对应于此新建模型的新条目。 该表还会显示以下状态：“正在处理”、“成功”、“失败”。

显示的状态反映了将数据集转换为语音模型的过程，如下所示。

| 状态 | 含义 |
| ----- | ------- |
| 正在处理 | 正在创建语音模型。 |
| 已成功 | 语音模型已创建并可部署。 |
| 已失败 | 语音模型在训练过程中由于多种原因（例如，察觉不到的数据问题或网络问题）而失败。 |

训练时间因处理的音频数据量和所选训练方法而异。 其范围可以为 30 分钟到 40 小时。 模型训练成功后，可以开始对其进行测试。 

> [!NOTE]
> 免费订阅 (F0) 用户可以同时训练一个语音字体。 标准订阅 (S0) 用户可以同时训练三个语音。 如果达到限制，请先等待，直至至少其中一种语音字体训练完毕，然后再试。

> [!NOTE]
> 训练自定义神经语音不免费。 请在此处查看[定价](https://azure.microsoft.com/pricing/details/cognitive-services/speech-services/)。 

> [!NOTE]
> 允许为每个订阅训练的语音模型的最大数目为 10 个（对于免费订阅 (F0) 用户）和 100 个（对于标准订阅 (S0) 用户）模型。

如果你使用神经语音定型功能，可选择定型针对实时流式处理场景进行优化的模型，或针对异步[长音频合成](long-audio-api.md)优化的 HD 神经模型。  

## <a name="test-your-voice-model"></a>测试语音模型

每次训练都将自动生成 100 个示例音频文件，以帮助你测试模型。 成功生成语音模型以后，可以对其先测试后部署，然后就可以使用了。

1.  导航到“文本转语音”>“自定义语音”> [项目名称] >“模型”。

2.  单击要测试的模型的名称。

3.  在“模型详细信息”页上，可以在“测试”选项卡下找到示例音频文件。 

语音质量取决于多个因素，包括训练数据的大小、录制内容的质量、脚本文件的准确性、训练数据中录制的语音与为预期用例设计的语音个性化匹配的程度，等等。 [查看此处以了解有关技术的功能和限制的详细信息，以及提高模型质量的最佳做法](/legal/cognitive-services/speech-service/custom-neural-voice/characteristics-and-limitations-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext)。 

## <a name="create-and-use-a-custom-voice-endpoint"></a>创建并使用自定义语音终结点

成功创建并测试语音模型以后，即可在自定义的文本转语音终结点中部署它。 然后即可在通过 REST API 发出文本转语音请求时使用此终结点来替代常用的终结点。 只能通过部署字体时所用的订阅来调用自定义终结点。

若要创建新的自定义语音终结点，请转到“文本转语音”>“自定义语音”>“终结点”。 选择“添加终结点”，并输入自定义终结点的 **名称** 和 **说明**。 然后选择要与此终结点关联的自定义语音模型。

单击“添加”按钮后，会在终结点表中看到新终结点的条目。 新终结点的实例化可能需要数分钟。 当部署状态为“成功”时，终结点便可供使用。

如果你始终不使用终结点，则可以将其“挂起”并“继续”。 当终结点在挂起后重新激活时，终结点 URL 将保持不变，因此你无需在应用程序中更改代码。 

你还可以将终结点更新为新模型。 若要更改模型，请确保新模型的名称与要更新的模型相同。 

> [!NOTE]
> 免费订阅 (F0) 用户只能部署一个模型。 标准订阅 (S0) 用户可以创建多达 50 个终结点，每个终结点具有自身的自定义语音。

> [!NOTE]
> 若要使用自定义语音，必须指定语音模型名称，直接使用 HTTP 请求中的自定义 URI，并使用同一订阅来通过 TTS 服务的身份验证。

部署终结点后，其名称将以链接的形式显示。 单击此链接可显示特定于该终结点的信息，例如终结点密钥、终结点 URL 和示例代码。

也可通过自定义语音门户对终结点进行联机测试。 若要测试终结点，请在“终结点详细信息”页中选择“检查终结点”。  此时会显示终结点测试页。 在文本框中输入要朗读的文本（采用纯文本或 [SSML 格式](speech-synthesis-markup.md)）。 若要收听以自定义语音字体朗读的文本，请选择“播放”。 此项测试功能会收取自定义语音识别合成使用费。

从功能上说，自定义终结点与用于文本转语音请求的标准终结点相同。 有关详细信息，请参阅 [REST API](rest-text-to-speech.md)。

## <a name="next-steps"></a>后续步骤

* [指南：录制语音样本](record-custom-voice-samples.md)
* [文本转语音 API 参考](rest-text-to-speech.md)
* [长音频 API](long-audio-api.md)