---
title: 创建自定义的语音的语音服务
titlesuffix: Azure Cognitive Services
description: 如果你已准备好将数据上传，请转到自定义语音门户。 创建或选择自定义语音项目。 项目必须共享正确语言/区域设置和数据的性别属性您打算使用语音培训。
services: cognitive-services
author: erhopf
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 05/06/2019
ms.author: erhopf
ms.openlocfilehash: 6189ea2866d1c16f994179df0179e29353e6c47d
ms.sourcegitcommit: 6f043a4da4454d5cb673377bb6c4ddd0ed30672d
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 05/08/2019
ms.locfileid: "65410723"
---
# <a name="create-a-custom-voice"></a>创建自定义语音

在中[准备数据以自定义语音](how-to-custom-voice-prepare-data.md)，我们介绍了可用于训练的自定义语音和不同的格式要求的不同数据类型。 一旦你已准备好你的数据，您可以开始将它们上载到[自定义语音门户](https://aka.ms/custom-voice-portal)，或通过自定义语音训练 API。 此处介绍的训练通过门户自定义语音的步骤。

> [!NOTE]
> 此页面假定你已阅读[开始使用自定义语音](how-to-custom-voice.md)并[准备数据以自定义语音](how-to-custom-voice-prepare-data.md)，并已创建了自定义语音项目。

检查所支持的自定义语音语言：[自定义的语言](language-support.md#customization)。

## <a name="upload-your-datasets"></a>上传数据集

如果你已准备好将数据上传，请转到[自定义语音门户](https://aka.ms/custom-voice-portal)。 创建或选择自定义语音项目。 项目必须共享正确语言/区域设置和数据的性别属性您打算使用语音培训。 例如，选择`en-GB`如果的录音必须在英语中完成与英国重音。

转到**数据**选项卡，单击**将数据上传**。 在向导中，选择正确的数据类型相匹配您已准备好。

上传每个数据集必须满足的要求您选择的数据类型。 请务必正确地设置格式数据，然后将其上载。 这可确保由自定义语音服务准确地处理数据。 转到[准备数据以自定义语音](how-to-custom-voice-prepare-data.md)和确保数据正确地将其设置格式。

> [!NOTE]
> 免费订阅 (F0) 用户可以同时上传两个数据集。 标准订阅 (S0) 用户可以同时上载 5 个数据集。 如果达到限制，请先等待，直至至少其中一个数据集导入完毕。 然后重试。

> [!NOTE]
> 允许每个订阅导入的数据集的最大数目是免费的 10 个.zip 文件订阅 (F0) 用户和标准订阅 (S0) 用户的 500。

只要你点击上载按钮，将自动验证数据集。 数据验证包括系列检查来验证其文件格式、 大小和采样率的音频文件。 如果任何修复错误并再次提交。 已成功启动数据导入请求时，应看到对应于刚上传的数据集的数据表中的条目。

下表显示了已导入数据集的处理状态：

| 状态 | 含义 |
| ----- | ------- |
| 正在处理 | 你的数据集已收到并处理。 |
| 已成功 | 你的数据集已验证，现在可能用于生成语音模型。 |
| 已失败 | 你的数据集已在由于多种原因，例如文件错误、 数据问题或网络问题而导致处理过程已失败。 |

完成验证后，可以看到你在中的数据集的每个匹配语音样本总数**语音样本**列。 如果已选择的数据类型需要长时间音频分段，此列仅反映了我们为你基于您的学习记录或者通过语音听录服务已分段的语音样本。 您可以进一步下载数据集验证，以查看详细信息的结果已成功导入的语音样本并且其映射的学习记录。 提示： 长时间音频分段可能需要多个一小时才能完成数据处理。

对于 EN-US 和 zh CN 数据集，可以进一步下载报表，以检查每个将录制的发音分数和噪音级别。 发音评分范围为 0 到 100。 评分低于 70 通常表示语音错误或脚本不匹配。 口音重可能会降低发音分数，影响生成的数字语音。

信噪比 (SNR) 高表明音频中的噪音少。 通过专业录音棚录音通常可以达到 50+ 的 SNR。 音频的 SNR 低于 20 可能导致生成的语音中出现明显的噪音。

考虑重写录制发音分数低或信噪比不佳的表述。 如果无法重新录制，可以从数据集中排除这些话语。

## <a name="build-your-custom-voice-model"></a>生成自定义语音模型

验证你的数据集后，可用于生成自定义语音模型。

1.  导航到**文本到语音转换 > 自定义语音 > 培训**。

2.  单击**训练模型**。

3.  接下来，输入**名称**并**说明**以帮助你识别此模型。

    请谨慎选择名称。 此处输入的名称将是在 SSML 输入过程中在请求中指定语音合成所需语音时使用的名称。 字母、 数字和一些标点符号字符，如-， \_，和 （，） 允许使用。 使用不同的语音模型的不同名称。

    通常使用“说明”字段来记录创建模型时所使用的数据集的名称。

4.  从**选择训练数据**页上，选择你想要用于定型的一个或多个数据集。 将其提交之前，请检查语音样本数。 您可以使用任意数量的 EN-US 和 zh CN 语音模型的语音样本进行启动。 对于其他区域设置，必须选择超过 2,000 个语音样本能够训练语音。

    > [!NOTE]
    > 将从训练删除重复的音频名称。 请确保你选择的数据集不包含跨多个.zip 文件相同的音频名称。

    > [!TIP]
    > 使用来自同一个演讲者数据集是必需的结果的质量。 如果您已提交用于定型的数据集包含总数不超过 6,000 不同语音样本，将训练统计参数合成技术通过语音模型。 在将训练数据超过了 6,000 不同语音样本总数的情况下，在将启动串联合成技术培训流程。 通常情况下串联技术可能会导致更自然和更高版本保真度语音结果。 [与自定义语音团队联系](mailto:speechsupport@microsoft.com)如果你想要训练模型的最新的神经 TTS 技术，可以生成等效于公开提供的数字语音[神经语音](language-support.md#neural-voices)。

5.  单击**训练**开始创建您的语音模型。

培训表显示到这个新创建的模型相对应的新项。 该表还显示的状态：处理、 成功、 失败。

显示的状态反映了将你的数据集转换为语音模型的过程，如下所示。

| 状态 | 含义 |
| ----- | ------- |
| 正在处理 | 正在创建你的语音模型。 |
| 已成功 | 语音模型已创建，并且可部署。 |
| 已失败 | 语音模型已定型由于多种原因，例如不可见的数据的问题或网络问题而失败。 |

训练时间因处理的音频数据量而异。 通常情况下，处理数百个表述需要大约 30 分钟的时间，处理 20,000 个表述需要 40 小时。 一旦成功模型定型，即可对其进行测试。

> [!NOTE]
> 免费订阅 (F0) 用户可以同时训练一个语音字体。 标准订阅 (S0) 用户可以同时训练三个语音。 如果达到限制，请先等待，直至至少其中一种语音字体训练完毕，然后再试。

> [!NOTE]
> 语音模型训练每个订阅允许的最大数目为 10 个免费订阅 (F0) 用户的模型和 100 之间的标准订阅 (S0) 用户。

## <a name="test-your-voice-model"></a>测试您的语音模型

成功生成语音字体以后，可以对其先测试后部署，然后就可以使用了。

1.  导航到**文本到语音转换 > 自定义语音 > 测试**。

2.  单击**添加测试**。

3.  选择你想要测试的一个或多个模型。

4.  提供要 voice(s) 要朗读的文本。 如果选择了一次测试多个模型，相同的文本将用于不同的模型的测试。

    > [!NOTE]
    > 文本的语言必须与语音字体的语言相同。 仅成功训练的模型可以进行测试。 在此步骤中支持仅纯文本。

5.  单击**创建**。

一旦你已提交你测试的请求，您将返回到测试页。 表中现在会有新请求的对应条目以及状态列。 可能需要数分钟来合成语音。 当状态列显示**Succeeded**，可以播放音频，或下载文本输入 （.txt 文件） 和音频输出 （.wav 文件），并进一步欣赏后者的质量。

用于测试，还可以查找测试结果中选择了每个模型的详细信息页。 转到**培训**卡，然后单击模型名称输入模型详细信息页。

## <a name="create-and-use-a-custom-voice-endpoint"></a>创建和使用自定义语音终结点

成功创建并测试语音模型以后，即可在自定义的文本转语音终结点中部署它。 然后即可在通过 REST API 发出文本转语音请求时使用此终结点来替代常用的终结点。 只能由具有用于部署该字体的订阅，可以调用自定义终结点。

若要创建新的自定义语音终结点，请转到**文本到语音转换 > 自定义语音 > 部署**。 选择**添加终结点**并输入**名称**并**说明**为自定义终结点。 然后选择你想要将与此终结点相关联的自定义语音模型。

单击后**添加**按钮，在终结点表中，将看到新的终结点的一个条目。 新终结点的实例化可能需要数分钟。 当部署状态为“成功”时，终结点便可供使用。

> [!NOTE]
> 免费订阅 (F0) 用户可以部署一个模型。 标准订阅 (S0) 用户可以创建最多 50 个终结点，每个都有其自己的自定义语音。

> [!NOTE]
> 若要使用自定义语音，必须指定语音模型名称、 直接在 HTTP 请求中使用自定义 URI 并使用同一个订阅通过 TTS 服务的身份验证。

部署你的终结点后，终结点名称将显示为链接。 单击链接以向你的终结点，例如终结点密钥、 终结点 URL 和示例代码显示特定的信息。

也可通过自定义语音门户对终结点进行联机测试。 若要测试你的终结点，请选择**检查终结点**从**终结点详细信息**页。 此时会显示终结点测试页。 输入要朗读的文本 (在任一纯文本或[SSML 格式](speech-synthesis-markup.md)在文本框中。 若要收听以自定义语音字体朗读的文本，请选择“播放”。 此测试的功能将根据你自定义语音合成的使用情况。

从功能上说，自定义终结点与用于文本转语音请求的标准终结点相同。 有关详细信息，请参阅 [REST API](rest-text-to-speech.md)。

## <a name="next-steps"></a>后续步骤

* [指南：记录您的语音示例](record-custom-voice-samples.md)
* [文本到语音转换 API 参考](rest-text-to-speech.md)
