---
title: 语音转文本常见问题解答
titleSuffix: Azure Cognitive Services
description: 获取有关语音转文本服务的常见问题的解答。
services: cognitive-services
author: PanosPeriorellis
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 08/20/2020
ms.author: panosper
ms.openlocfilehash: 32f6a9dae1a5b0be604b53d814ebc85cb7813b91
ms.sourcegitcommit: 9eda79ea41c60d58a4ceab63d424d6866b38b82d
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 11/30/2020
ms.locfileid: "96353759"
---
# <a name="speech-to-text-frequently-asked-questions"></a>语音转文本常见问题解答

如果在本常见问题解答中找不到你的问题的解答，请检查[其他支持选项](../cognitive-services-support-options.md?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext%253fcontext%253d%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext)。

## <a name="general"></a>常规

**问：基线模型和自定义语音转文本模型之间有什么区别？**

**答**：基线模型已使用 Microsoft 拥有的数据定型，并且已部署在云中。 你可以使用自定义模型来调整模型，以便更好地适应具有特定环境噪音或语言的具体环境。 工厂、汽车或嘈杂的街道需要适应的声学模型。 生物学、物理学、放射学、产品名称和自定义首字母缩略词等主题需要适应的语言模型。

**问：如果想要使用基线模型，从何处开始？**

**答**：首先，获取 [订阅密钥](overview.md#try-the-speech-service-for-free)。 如果想要对预先部署的基线模型进行 REST 调用，请参阅 [REST API](./overview.md#reference-docs)。 如果想要使用 WebSocket，请[下载 SDK](speech-sdk.md)。

**问：是否始终需要生成自定义语音识别模型？**

**答**：否。 如果应用程序使用通用的日常语言，则无需自定义模型。 如果应用程序用于背景噪音很小或无背景噪音的环境，则无需自定义模型。

你可以在门户中部署基线模型和自定义模型，并针对这些模型运行准确度测试。 可以使用此功能衡量基线模型与自定义模型的准确度。

**问：如何知道何时完成数据集或模型的处理？**

**答**：目前，表中模型或数据集的状态是唯一可以了解的途径。 处理完成后，状态是“成功”  。

**问：能否创建多个模型？**

**答**：集合中可以拥有的模型数量没有限制。

**问：我意识到自己犯了一个错误。** 如何取消正在进行的数据导入或模型创建？

**答**：当前无法回滚声学或语言适应过程。 可以在导入的数据和模型处于终点状态时删除它们。

**问：搜索和听写模型与对话模型之间有什么区别？**

**答**：你可以在语音服务中从多个基线模型中进行选择。 对话模型适用于识别以对话方式说出的语音。 此模型非常适合转录电话。 搜索和听写模型非常适合语音触发的应用。 通用模型是一种旨在解决这两种情况的新模型。 在大多数区域设置中，通用模型目前处于或高于对话式模型的质量级别。

**问：能否更新现有模型（模型堆叠）？**

**答**：无法更新现有模型。 一种解决方案是将旧数据集与新数据集合并，然后重新适应。

旧数据集和新数据集必须合并为单个 .zip 文件（用于声学数据）或 .txt 文件（用于语言数据）。 适应完成后，需要重新部署新的更新后模型以获取新的终结点

**问：当新版本的基线可用时，是否会自动更新我的部署？**

**答**：部署不会自动更新。

如果已调整并部署了具有基线 V1.0 的模型，该部署将保持原样。 客户可以解除已部署的模型，使用较新版本的基线重新调整并重新部署。

**问：能否下载模型并在本地运行？**

**答**：无法下载模型并在本地执行。

**问：是否会记录我的请求？**

**答**：默认情况下不记录请求（既不进行音频记录，也不进行听录）。 如果需要，可以在[创建自定义终结点](./how-to-custom-speech-train-model.md)时选择“从此终结点记录内容”选项以启用跟踪。 然后，请求会记录在 Azure 的安全存储中。

**问：我的请求是否受到限制？**

**答**：请参阅 [语音服务配额和限制](speech-services-quotas-and-limits.md)。

**问：双声道音频如何收费？**

**答**：如果你单独提交每个声道（每个声道在其自己的文件中），则将按每个文件的持续时间对你收费。 如果你提交单个文件，其中每个声道都一起多路复用，则按单个文件的持续时间对你收费。 有关定价的详细信息，请参阅 [Azure 认知服务定价页](https://azure.microsoft.com/pricing/details/cognitive-services/speech-services/)。

> [!IMPORTANT]
> 如果有禁止使用自定义语音识别服务的其他隐私问题，请联系其中一个支持渠道。

## <a name="increasing-concurrency"></a>提高并发性
请参阅[语音服务配额和限制](speech-services-quotas-and-limits.md)。


## <a name="importing-data"></a>导入数据

**问：数据集大小的限制是什么？为何限制？**

**答**：之所以有此限制，是由于 HTTP 上传文件大小存在限制。 有关实际限制，请参阅[语音服务配额和限制](speech-services-quotas-and-limits.md)。

**问：是否可以压缩文本文件，以便上传更大的文本文件？**

**答**：否。 目前，仅允许未压缩的文本文件。

**问：数据报告表明，有言语导入失败。问题出在哪里？**

**答**：未能上传文件中 100% 的话语并不是什么问题。 如果成功导入了声学或语言数据集中的绝大多数话语（如 95% 以上的话语），则该数据集可用。 但是，建议尝试了解话语失败的原因并解决问题。 大多数常见问题（如格式设置错误）很容易修复。

## <a name="creating-an-acoustic-model"></a>创建声学模型

**问：需要多少声学数据？**

**答**：建议开始时先使用 30 分钟到 1 小时的声学数据。

**问：应该收集哪些数据？**

**答**：收集尽可能接近于应用程序方案和用例的数据。 数据收集应在设备、环境和说话人类型方面与目标应用程序和用户匹配。 一般而言，应从尽可能广泛的说话人中收集数据。

**问：如何收集声学数据？**

**答**：可以创建独立的数据收集应用程序，或使用现成的录音软件。 你还可以创建一个用于记录音频数据并使用该数据的应用程序版本。

**问：是否需要自行转录适应数据？**

**答**：能！ 可以自行转录或使用专业听录服务进行转录。 有些用户更喜欢使用专业听录器，而其他用户则使用众包或自己进行听录。

## <a name="accuracy-testing"></a>精确度测试

**问：是否可以使用自定义语言模型对我的自定义声学模型执行离线测试？**

**答**：可以，只需在设置离线测试时从下拉菜单中选择自定义语言模型即可。

**问：是否可以使用自定义声学模型对我的自定义语言模型执行离线测试？**

**答**：可以，只需在设置脱机测试时，选择下拉菜单中的自定义声学模型即可。

**问：什么是字错误率 (WER) 以及如何计算此错误率？**

**答**：WER 是用于语音识别的评估指标。 WER 由错误总数（包括插入、删除和替换）除以引用听录中的总字数得出。 有关详细信息，请参阅[字错误率](https://en.wikipedia.org/wiki/Word_error_rate)。

**问：如何确定准确度测试的结果是否良好？**

**答**：测试结果对基线模型和自定义模型进行了比较。 应以超越基线模型为目标，使自定义模型变得有价值。

**问：如何确定基础模型的 WER 以便查看是否有改进？**

**答**：离线测试结果显示了自定义模型的基线准确度以及与基线相比的改进情况。

## <a name="creating-a-language-model"></a>创建语言模型

**问：需要上传多少文本数据？**

**答**：这取决于应用程序中使用的词汇和短语与初始语言模型存在多大差异。 对于所有新字词，尽可能多地提供这些字的使用示例很有用。 对于应用程序中使用的常用短语，在语言数据中添加短语也很有用，因为这会告知系统也要侦听这些术语。 在语言数据集中至少有 100 句话语（通常几百句或更多话语）是很常见的。 另外，如果预期某些类型的查询比其他查询更加常用，则可以在数据集中插入常用查询的多个副本。

**问：能否只上传字词列表？**

**答**：上传字词列表会将字词添加到词汇中，但不会告知系统这些字词的通常用法。 通过提供完整或部分话语（用户很可能会说事物的句子或短语），语言模型可以学习这些新字词及其用法。 自定义语言模型不仅适用于向系统中添加新字词，还适用于调整应用程序已知字词的概率。 提供完整话语可帮助系统更好地学习。

## <a name="tenant-model-custom-speech-with-microsoft-365-data"></a>与 Microsoft 365 数据自定义语音的租户模型 () 

**问：租户模型中包含哪些信息，如何创建？**

**答：** 租户模型是使用 [公用组](https://support.microsoft.com/office/learn-about-microsoft-365-groups-b565caa1-5c40-40ef-9915-60fdb2d97fa2) 电子邮件和文档生成的，你的组织中的任何人都可以看到该模型。

**问：租户模型改进了哪些语音体验？**

**答：** 启用并发布租户模型后，它将用于改进使用语音服务生成的任何企业应用程序的识别;这也会传递一个用户 Azure AD 标记，指示企业的成员身份。

为语音服务应用程序创建租户模型时，不会更改内置于 Microsoft 365 中的语音体验，如听写和 PowerPoint 字幕。

## <a name="next-steps"></a>后续步骤

- [故障排除](troubleshooting.md)
- [发行说明](releasenotes.md)